{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('train_call.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data2 = data\n",
    "data = data.drop(data.index[[1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples = pd.read_csv('train_clinical.txt', sep='\\t')\n",
    "samples = samples.set_index('Sample', drop=False).rename_axis(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2824</th>\n",
       "      <th>2825</th>\n",
       "      <th>2826</th>\n",
       "      <th>2827</th>\n",
       "      <th>2828</th>\n",
       "      <th>2829</th>\n",
       "      <th>2830</th>\n",
       "      <th>2831</th>\n",
       "      <th>2832</th>\n",
       "      <th>2833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Array.129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2834 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "Array.129     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "Array.34      0     0     0     0     0     0     0     0     0     0  ...   \n",
       "Array.67      0     0     0     0     0     0     0     0     0     0  ...   \n",
       "Array.24      0     0     0     0     0     0     0    -1     0     0  ...   \n",
       "Array.22      0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "           2824  2825  2826  2827  2828  2829  2830  2831  2832  2833  \n",
       "Array.129     2     2     2     2     0     1     1     1     1     1  \n",
       "Array.34      1     1     1     1     1     1     1     1     1     1  \n",
       "Array.67      1     1     1     1     1     1     1     1     1     1  \n",
       "Array.24      0     0     0     0     0     0     0     0     0     0  \n",
       "Array.22      1     1     1     1     1     1     1     1     1     1  \n",
       "\n",
       "[5 rows x 2834 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_simplified = data.drop(\"Chromosome\")\n",
    "data_simplified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Subgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Array.129</th>\n",
       "      <td>Array.129</td>\n",
       "      <td>HER2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.34</th>\n",
       "      <td>Array.34</td>\n",
       "      <td>HR+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.67</th>\n",
       "      <td>Array.67</td>\n",
       "      <td>HR+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.24</th>\n",
       "      <td>Array.24</td>\n",
       "      <td>Triple Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Array.22</th>\n",
       "      <td>Array.22</td>\n",
       "      <td>Triple Neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sample    Subgroup\n",
       "Array.129  Array.129       HER2+\n",
       "Array.34    Array.34         HR+\n",
       "Array.67    Array.67         HR+\n",
       "Array.24    Array.24  Triple Neg\n",
       "Array.22    Array.22  Triple Neg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data.columns)\n",
    "\n",
    "newsamples = samples[\"Subgroup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_simplified[features]\n",
    "y = newsamples\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       HER2+       1.00      0.86      0.92         7\n",
      "         HR+       0.60      0.86      0.71         7\n",
      "  Triple Neg       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.78      0.74      0.74        20\n",
      "weighted avg       0.78      0.75      0.75        20\n",
      "\n",
      "Confusion matrix:\n",
      " [[6 1 0]\n",
      " [0 6 1]\n",
      " [0 3 3]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2184, 2213, 2219, 2206, 851, 853, 1904, 1068, 2211, 301, 764, 1059, 2108, 2026, 833, 692, 385, 2024, 68, 2017, 2116, 856, 1656, 471, 854, 998, 623, 1883, 843, 757, 2162, 837, 743, 2818, 2751, 1678, 1663, 2205, 1910, 2419, 1972, 855, 2756, 478, 860, 1644, 766, 2203, 174, 2208, 861, 721, 389, 2207, 835, 790, 1732, 2198, 476, 1667]\n"
     ]
    }
   ],
   "source": [
    "# Compute the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "important_features_dict = {}\n",
    "for idx, val in enumerate(rf.feature_importances_):\n",
    "    important_features_dict[idx] = val\n",
    "\n",
    "important_features_list = sorted(important_features_dict,\n",
    "                                 key=important_features_dict.get,\n",
    "                                 reverse=True)\n",
    "\n",
    "print(important_features_list[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_features_df = data_simplified[[2184, 2213, 2219, 2206, 851, 853, 1904, 1068, 2211, 301, 764, 1059, 2108, 2026, 833, 692, 385, 2024, 68, 2017, 2116, 856, 1656, 471, 854, 998, 623, 1883, 843, 757, 2162, 837, 743, 2818, 2751, 1678, 1663, 2205, 1910, 2419, 1972, 855, 2756, 478, 860, 1644, 766, 2203, 174, 2208, 861, 721, 389, 2207, 835, 790, 1732, 2198, 476, 1667]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Accuracy: 0.810 (0.058)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean, std\n",
    "\n",
    "X = new_features_df\n",
    "y = newsamples\n",
    "\n",
    "cv = KFold()\n",
    "cv1 = LeaveOneOut()\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# fit model\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "#inner k fold\n",
    "best_model = GridSearchCV(model, param_grid = param_grid, scoring = 'accuracy', cv=cv,verbose=20,n_jobs=-1)\n",
    "\n",
    "best_model.fit(X,y)\n",
    "\n",
    "#outer k fold. Use k-fold twice.\n",
    "scores = cross_val_score(best_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is nested cross-validation working and priniting accuracies. However I'm not sure how to extract the best model out of all the 5 cross validated models. Probably bne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.80\n",
      "Test set accuracy: 0.75\n",
      "Test set accuracy: 0.85\n",
      "Test set accuracy: 0.80\n",
      "Test set accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "nested_cv_scores = []\n",
    "i = -1\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']}\n",
    "    \n",
    "    # Perform grid search with cross-validation on the inner loop\n",
    "    grid_search = GridSearchCV(rf, param_grid = param_grid, cv=inner_cv, scoring='accuracy')\n",
    "    result = grid_search.fit(X_train, y_train.ravel())\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    # Evaluate the model on the test set and append the score to the list\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    nested_cv_scores.append(test_score)\n",
    "    print(f\"Test set accuracy: {test_score:.2f}\")\n",
    "    \n",
    "    #probably here i need some kind of if statement to extract the final best cross validated model. something like\n",
    "    i = i + 1\n",
    "    if test_score > nested_cv_scores[i]:\n",
    "        GOAT_model = best_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GOAT_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zx/9wq85h090yj8pmk6sbvl93n80000gn/T/ipykernel_2575/481875512.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGOAT_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'GOAT_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below here is the graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       HER2+       1.00      1.00      1.00         6\n",
      "         HR+       0.88      0.88      0.88         8\n",
      "  Triple Neg       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.90      0.90      0.90        20\n",
      "weighted avg       0.90      0.90      0.90        20\n",
      "\n",
      "Confusion matrix:\n",
      " [[6 0 0]\n",
      " [0 7 1]\n",
      " [0 1 5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    " # define the evaluation procedure\n",
    " cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " # evaluate the model and collect the results\n",
    " scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    " return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9, 0.9, 1. , 0.8, 0.8, 0.9, 0.5, 0.8, 0.9, 1. , 0.9, 0.9, 0.9,\n",
       "       0.8, 0.7, 0.7, 1. , 0.8, 0.5, 0.9, 0.9, 0.8, 1. , 0.9, 0.8, 0.9,\n",
       "       0.8, 0.9, 0.8, 0.7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(rf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
